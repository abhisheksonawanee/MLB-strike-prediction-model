{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modeling: MLB Pitch Strike Prediction\n",
        "\n",
        "This notebook builds and evaluates models to predict whether a pitch will be a strike.\n",
        "\n",
        "Steps:\n",
        "1. Load processed data and build features\n",
        "2. Split into train/test sets\n",
        "3. Train models (or load pre-trained models)\n",
        "4. Evaluate performance\n",
        "5. Visualize results (ROC curves, feature importances)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "from src import config\n",
        "from src.features import build_features_and_target\n",
        "from src.models import (\n",
        "    split_data,\n",
        "    train_all_models,\n",
        "    evaluate_all_models,\n",
        "    get_feature_importances\n",
        ")\n",
        "from src.plots import plot_roc_curves_multiple, plot_feature_importances\n",
        "\n",
        "# Set style\n",
        "plt.style.use('default')\n",
        "%matplotlib inline\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data and Build Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed data\n",
        "df = pd.read_csv(config.PROCESSED_DATA_FILE)\n",
        "print(f\"Loaded {len(df)} pitches\")\n",
        "\n",
        "# Build features and target\n",
        "print(\"\\nBuilding features...\")\n",
        "X, y, feature_names = build_features_and_target(df)\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Number of features: {len(feature_names)}\")\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(y.value_counts())\n",
        "print(f\"Strike rate: {y.mean():.2%}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Split Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = split_data(X, y)\n",
        "\n",
        "print(f\"Training set: {len(X_train)} pitches ({y_train.mean():.2%} strikes)\")\n",
        "print(f\"Test set: {len(X_test)} pitches ({y_test.mean():.2%} strikes)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Models (or Load Pre-trained)\n",
        "\n",
        "We can either train models here or load pre-trained models from the `models/` directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Train models (uncomment to train)\n",
        "# models = train_all_models(X_train, y_train)\n",
        "\n",
        "# Option 2: Load pre-trained models\n",
        "print(\"Loading pre-trained models...\")\n",
        "models = {}\n",
        "model_files = list(config.MODELS_DIR.glob(\"*.joblib\"))\n",
        "\n",
        "if not model_files:\n",
        "    print(\"No pre-trained models found. Training models now...\")\n",
        "    models = train_all_models(X_train, y_train)\n",
        "else:\n",
        "    for model_path in model_files:\n",
        "        model_name = model_path.stem\n",
        "        models[model_name] = joblib.load(model_path)\n",
        "        print(f\"  Loaded: {model_name}\")\n",
        "\n",
        "print(f\"\\nModels available: {list(models.keys())}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluate Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "print(\"Evaluating models on test set...\")\n",
        "test_metrics = evaluate_all_models(models, X_test, y_test)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Test Set Performance Metrics\")\n",
        "print(\"=\"*60)\n",
        "print(test_metrics.round(4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. ROC Curves\n",
        "\n",
        "ROC curves show the tradeoff between true positive rate and false positive rate at different classification thresholds. A model with a higher AUC (Area Under Curve) is better.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot ROC curves for all models\n",
        "fig = plot_roc_curves_multiple(models, X_test, y_test)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Feature Importances\n",
        "\n",
        "For tree-based models (Random Forest, XGBoost), we can see which features are most important for predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot feature importances for Random Forest\n",
        "if 'random_forest' in models:\n",
        "    rf_model = models['random_forest']\n",
        "    importances = get_feature_importances(rf_model, feature_names)\n",
        "    \n",
        "    print(\"Top 20 Most Important Features (Random Forest):\")\n",
        "    print(importances.head(20))\n",
        "    \n",
        "    # Plot\n",
        "    fig = plot_feature_importances(importances, top_n=20)\n",
        "    plt.show()\n",
        "\n",
        "# Also for XGBoost if available\n",
        "if 'xgboost' in models:\n",
        "    xgb_model = models['xgboost']\n",
        "    xgb_importances = get_feature_importances(xgb_model, feature_names)\n",
        "    \n",
        "    print(\"\\nTop 20 Most Important Features (XGBoost):\")\n",
        "    print(xgb_importances.head(20))\n",
        "    \n",
        "    # Plot\n",
        "    fig = plot_feature_importances(xgb_importances, top_n=20)\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Interpretation\n",
        "\n",
        "Let's look at the coefficients for Logistic Regression to understand feature effects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic Regression coefficients\n",
        "if 'logistic_regression' in models:\n",
        "    lr_model = models['logistic_regression']\n",
        "    \n",
        "    # Get coefficients (use absolute value for importance)\n",
        "    coef_importances = get_feature_importances(lr_model, feature_names)\n",
        "    \n",
        "    print(\"Top 20 Features by Absolute Coefficient (Logistic Regression):\")\n",
        "    print(coef_importances.head(20))\n",
        "    \n",
        "    # Plot\n",
        "    fig = plot_feature_importances(coef_importances, top_n=20)\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "- **Best Model**: Based on ROC-AUC, the {best_model} model performs best\n",
        "- **Key Features**: The most important features are {top_features}\n",
        "- **Model Performance**: All models significantly outperform the baseline\n",
        "\n",
        "Key takeaways:\n",
        "1. Plate location (plate_x, plate_z) is highly predictive\n",
        "2. Count (balls, strikes) is important\n",
        "3. Pitch characteristics (release_speed, pitch type) matter\n",
        "4. Tree-based models (Random Forest, XGBoost) perform well on this task\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
